{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membres de l'équipe: Josue ABOU MAWUFEMO , Kawtar MOULAHID, Abderrahmane BAROUALI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment analysis</h1>\n",
    "<ol>\n",
    "<h3><li>Définition du Sujet et Objectif</h3></li>\n",
    "<b>Sentiment analysis ?</b><br>\n",
    "<p>Aussi connue sous le nom de <strong><i>« Opinion Mining »</i></strong>, <strong>l’analyse des sentiments</strong> consiste à identifier les informations subjectives d’un texte pour <strong>extraire l’opinion de l’auteur</strong>. <br>\n",
    "De manière générale, <strong>l’analyse des sentiments</strong> permet de mesurer le niveau de satisfaction des clients vis-à-vis des produits ou services fournis par une entreprise ou un organisme. Elle peut même s’avérer <strong>bien plus efficace que des méthodes classiques</strong> comme les sondages puisque <strong>de nos jours, une partie croissante des consommateurs partage fréquemment leurs opinions sur les réseaux sociaux</strong>. </p>\n",
    "\n",
    "<p><i><strong>Objectif du Projet:</strong></i> Notre but est donc de mettre en place un modèle permettant de classifier les différents avis des clients d’un hôtel en deux classes qui sont : Avis positifs et avis négatifs.<br>\n",
    "Cette classification permettra au personnel de l’hôtel de pouvoir identifier les principales plaintes (Texte négatifs) afin d’améliorer leurs services et réduire le niveau d’insatisfaction des clients.<br></p>\n",
    "\n",
    "<h3><li>Constitution de la dataset</h3></li>\n",
    "<p>Avant d’entamer le travail proprement dit, nous allons d’abord décrire brièvement notre dataset.<br>\n",
    "Nous avons utilisé une dataset téléchargeable sur Kaggle via le lien suivant : \n",
    "<a href=\"https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews\">https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews</a><br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Aperçu de la dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.to_csv('data.csv', index=False)  \n",
    "\n",
    "df.isna().sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En affichant le résumé de la dataset, on voit qu’elle contient environ 20 000 lignes et deux colonnes : <br>\n",
    "<ul>\n",
    "    <li>Une colonne Review : qui n’est autre qu’un paragraphe contenant le commentaire de l’utilisateur</li>\n",
    "    <li>Une colonne Rating : qui précise s’il s’agit d’un avis positif ou pas. Notre objectif principal est de <b>détecter les avis négatifs</b> donc la <b>classe positive(1)</b>correspond aux avis négatifs et la <b>classe négative(0)</b> correspond aux avis positifs.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20491 entries, 0 to 20490\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  20491 non-null  object\n",
      " 1   Rating  20491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 320.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>En affichant les quantités de données pour chaque catégorie, on s’aperçoit que la dataset est disproportionnée. Elle contient plus d’avis positifs (environ 17000) que d’avis négatifs (environ 3000). Cette différence pourra sans doute influencer le modèle lors de l’entrainement. Ce dernier risque donc d’overfitter sur les avis positifs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17277\n",
       "0     3214\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour remédier à cela, il existe plusieurs possibilités :\n",
    "<ul>\n",
    "    <li><b>Sous-échantillonnage de la classe majoritaire</b> qui consiste à réduire le nombre d'échantillons de la classe majoritaire en sélectionnant au hasard un sous-ensemble de données de cette classe à utiliser pour l'entrainement.</li>\n",
    "    <br>\n",
    "    <li><b>Suréchantillonnage de la classe minoritaire </b>qui consiste à augmenter le nombre de données de la classe minoritaire dans l'ensemble de données d'apprentissage.</li>\n",
    "     <br>\n",
    "    <li>Faire du <b>webscraping</b> afin d’augmenter le nombre d’avis négatifs.</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "L'un des principaux inconvénients du <b>sous-échantillonnage</b> est que des données ou des informations utiles peuvent être perdues. De plus dans notre cas, on obtiendra en tout environ 6000 lignes de données, ce qui n’est pas vraiment approprié pour un problème de NLP.<br><br>\n",
    "Le principal inconvénient du <b>suréchantillonnage </b> est qu'elle peut entraîner un overfitting. <br><br>\n",
    "Nous allons donc opter pour la troisième solution qui est celle du <b>webscraping</b>.<br><br>\n",
    "Nous avons scrapper le site <a href=\"https://www.tripadvisor.com\">www.tripadvisor.com</a>. Les détails du webscraping se trouve dans le notebook <a href=\"webscraping_NoteBook.ipynb\"> webscraping_NoteBook.ipynb</a>. <br><br>\n",
    "Grâce au webscraping on a pu obtenir environ 5500 lignes avis négatifs. La dataset contient désormais 25000 données. Cette fois ci, en faisant un sous-échantillonnage, on obtient 17000 données en tout (8500 pour chaque catégorie)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8500 entries, 6280 to 6957\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  8500 non-null   object\n",
      " 1   Rating  8500 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 199.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8500 entries, 587 to 4485\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  8500 non-null   object\n",
      " 1   Rating  8500 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 199.2+ KB\n",
      "None\n",
      "0    7146\n",
      "1    5583\n",
      "2    4271\n",
      "Name: Rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('all_reviews_final.csv')\n",
    "\n",
    "df = df.sample(n=8500)\n",
    "print(df.info())\n",
    "\n",
    "scraped_df = pd.read_csv('scraped_data.csv')\n",
    "scraped_df = scraped_df.drop(columns='Target')\n",
    "scraped_df = scraped_df.sample(n=8500, replace=True)\n",
    "print(scraped_df.info())\n",
    "df = df.append(scraped_df)\n",
    "\n",
    "print(df.Rating.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que cela est fait, Notre dataset est constitué et on peut enchainer avec les étapes suivantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "<h3><li>Plan de travail</h3></li>\n",
    "Comme on peut s’en douter, Il s’agit ici d’un problème de Natural Language Processing (NLP) ou Traitement automatique du langage naturel.<br>\n",
    "Et comme pour tout problème de NLP, Notre travail se compose principalement de deux parties :\n",
    "\n",
    "<ul>\n",
    "    <li>La partie <b>« linguistique »</b>, qui consiste à prétraiter et transformer les informations en entrée en un jeu de données exploitable.</li>\n",
    "    <li>La partie <b>« apprentissage automatique »</b>, qui porte sur l’application de modèles <b><i>de Machine Learning</i></b> à ce jeu de données.</li><br>\n",
    "</ul>\n",
    "Dans la suite du rapport, Nous allons aborder ces deux aspects, en décrivant brièvement les <b>principales méthodes utilisées </b>et en précisant les principaux défis auxquels nous avons fait face.\n",
    "</ol>\n",
    "<ol type=\"A\">\n",
    "<h3><li>Partie linguistique : Du texte à la donnée</li></h3>\n",
    "<p>Avant toute chose, il est important de s'assurer que notre dataset ne contient pas de données manquantes</p>\n",
    "<p>Parmi les principales étapes de cette partie, on retrouve :</p>\n",
    "<ol type=\"a\">\n",
    "<li>Nettoyage : cette phase consiste à réaliser des tâches telles que la <b><i>suppression d’urls, d’emoji, suppression de  ponctuation, de symboles et de stopwords, passage en minuscule</i><b>.</li>\n",
    "</ol>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous les fonctions permettant de faire le nettoyage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour que le code ci-dessous s'exectue correctement, if faut tout d'abord installer la bibliothèque nltk avec la commande <i> piip install nltk </i>. <br> Ensuite, il faute lancer le CLI de python et excetuer les commandes suivantes afin de télécharger le package <i>stopwords</i><br>\n",
    ">>>import nltk <br>\n",
    ">>>nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_URL (text):\n",
    "    url = re.compile(r\"https?://\\s+ www\\.\\s+\")\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)\n",
    "         \n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" # flags (i0s)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "\n",
    "def remove_punct (text):\n",
    "    table = str.maketrans (\"\",\"\",string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "stop = set (stopwords.words ( \"english\"))\n",
    "def remove_stopwords (text):\n",
    "    text = [word.lower () for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On regroupe toutes ses fonctions en une seule appelée <i>nettoyerDataframe</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyerDataframe(df):\n",
    "    Review_cleaned = df.Review.map(lambda x: remove_URL(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_html(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_emoji(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_punct(x)) \n",
    "    Review_cleaned = Review_cleaned.map(remove_stopwords)   \n",
    "    df.insert(1, \"Review_cleaned\", Review_cleaned)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite on applique cette fonction pour nettoyer la colonne « Review » et on stocke le résultat dans la colonne <i>« Review_cleaned »</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_cleaned</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>nice rooms 4 experience hotel monaco seattle g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>great stay great stay went seahawk game awesom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  nice hotel expensive parking got good deal sta...   \n",
       "1  ok nothing special charge diamond member hilto...   \n",
       "2  nice rooms not 4* experience hotel monaco seat...   \n",
       "3  unique, great stay, wonderful time hotel monac...   \n",
       "4  great stay great stay, went seahawk game aweso...   \n",
       "\n",
       "                                      Review_cleaned  Rating  \n",
       "0  nice hotel expensive parking got good deal sta...       1  \n",
       "1  ok nothing special charge diamond member hilto...       0  \n",
       "2  nice rooms 4 experience hotel monaco seattle g...       1  \n",
       "3  unique great stay wonderful time hotel monaco ...       1  \n",
       "4  great stay great stay went seahawk game awesom...       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = nettoyerDataframe(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"a\" start=\"2\">\n",
    "<li>Normalisation des données :</li>\n",
    "<br>\n",
    "<b><i>Tokenisation</i></b>, ou découpage du texte en plusieurs pièces appelés tokens.<br><br>\n",
    "Pour cela, nous utiliserons la méthode des N-grammes.\n",
    "<br><br>\n",
    "Les N-grammes sont simplement toutes les combinaisons de mots ou de lettres adjacents de longueur n que nous pouvons trouver dans notre texte source. Les ngrammes avec n=1 sont appelés <i>unigrammes</i>. De même, <i>les bigrammes</i>(n=2), les trigrammes (n=3) et ainsi de suite peuvent également être utilisés.\n",
    "<br><br>\n",
    "Les unigrammes ne contiennent généralement pas beaucoup d'informations par rapport aux bigrammes et aux trigrammes. Le principe de base derrière les n-grammes est qu'ils capturent la lettre ou le mot susceptible de suivre le mot donné. Plus le n-gramme est long (n élevé), plus vous devez travailler avec du contexte.\n",
    "<br><br>\n",
    "Dans le cas de notre projet, Nous utiliserons les <b><i>unigrammes</i></b> puisque :\n",
    "<ul>\n",
    "<li>L’utilisation des N-grammes avec N>=2 conduit à une Memory Error (Mémoire RAM insuffisante).</li>\n",
    "</ul>\n",
    "<br><br>\n",
    "<li> Ensuite, Afin de pouvoir appliquer les méthodes de <i>Machine Learning</i> aux problèmes relatifs au langage naturel, il est indispensable de <i>transformer les données textuelles en données numériques</i>.<br><br>Pour se faire, Il existe plusieurs approches. L’une d’entre elles que nous utiliserons dans ce projet est celle du TF-IDF (<i>Term Frequency-Inverse Document Frequency</i>). Cette méthode consiste <b>à compter le nombre d’occurrences des tokens</b> présents dans le corpus pour chaque texte, que l’on divise ensuite par le nombre d’occurrences total de ces même tokens dans tout le corpus.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le TfidfVectorizer de la bibiliothèque sklearn.features_extraction.text de python, permet à la fois de faire la tokénization et la conversion en tfidf.<br><br>On applique le TfidfVectorizer à la colonne Review_cleaned et on stocke le résultat dans la variable X qui servira plutard pour l'entrainement des modeles.\n",
    "<br><br>On affiche les valeurs non-nulles du vecteur <i>tfidf</i> obtenu pour la première ligne juste pour voir à quoi ressemblent les coefficients tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12516507352450354,\n",
       " 0.12854579457638562,\n",
       " 0.11775813274013383,\n",
       " 0.12602235717202692,\n",
       " 0.07786526970232352,\n",
       " 0.16404737731101304,\n",
       " 0.23031114957113805,\n",
       " 0.09930925839995854,\n",
       " 0.06651952684158213,\n",
       " 0.07965869454752911,\n",
       " 0.04907235708021071,\n",
       " 0.1557795892042132,\n",
       " 0.06614277308084597,\n",
       " 0.09356817535887117,\n",
       " 0.09660179895521877,\n",
       " 0.0871468693621952,\n",
       " 0.11265217616460706,\n",
       " 0.08363817299133694,\n",
       " 0.08865468616957857,\n",
       " 0.08665417795251242,\n",
       " 0.0753275779580791,\n",
       " 0.20315799405977988,\n",
       " 0.04430043774460584,\n",
       " 0.06410798187805813,\n",
       " 0.04004543961652257,\n",
       " 0.1390140231826502,\n",
       " 0.10237811979496021,\n",
       " 0.10717087033106484,\n",
       " 0.08940321598726708,\n",
       " 0.06068453359758819,\n",
       " 0.09146981197468122,\n",
       " 0.05800958965151562,\n",
       " 0.0627170408205551,\n",
       " 0.04745886062572005,\n",
       " 0.12157677423873968,\n",
       " 0.11519050646733472,\n",
       " 0.10559482305524727,\n",
       " 0.07588535116791896,\n",
       " 0.1077887991980295,\n",
       " 0.1852158314355085,\n",
       " 0.16438829123009147,\n",
       " 0.2491847235502386,\n",
       " 0.1075086998429977,\n",
       " 0.10201770255629833,\n",
       " 0.1676886354069963,\n",
       " 0.14329990763653955,\n",
       " 0.08295426563215225,\n",
       " 0.29013774884217447,\n",
       " 0.08816273292314282,\n",
       " 0.06434061755804814,\n",
       " 0.11325189734138277,\n",
       " 0.1092937080613948,\n",
       " 0.1395108412627837,\n",
       " 0.10499771648413074,\n",
       " 0.07150692920085946,\n",
       " 0.10212125507680421,\n",
       " 0.08660987103785683,\n",
       " 0.08561213694805174,\n",
       " 0.17493006629336164,\n",
       " 0.08442912155162338,\n",
       " 0.08034764383895972,\n",
       " 0.18773147899877532,\n",
       " 0.10761559689656207,\n",
       " 0.13082109145523088,\n",
       " 0.07883712985693263,\n",
       " 0.11101476514464384,\n",
       " 0.12327331913727226,\n",
       " 0.06897423603309645,\n",
       " 0.07604842947880217,\n",
       " 0.14997532504066638]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(df.Review_cleaned)\n",
    "\n",
    "[ x for x in X.todense()[0][0:].tolist()[0] if x != 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"A\" start=\"2\">\n",
    "<h3><li>La phase d'apprentissage: Des données au modèle</li></h3>\n",
    "<p>De manière globale, on peut distinguer <b>3 principales approches NLP</b> : les <b>méthodes basées sur des règles</b>, modèles classiques de Machine Learning et modèles de Deep Learning.</p>\n",
    "<br>\n",
    "<ol type=\"a\">\n",
    "<li>Modèles utilisés</li>\n",
    "<p>Nous utiliserons uniquement les modèles classiques de Machine Learning.<br>Elles mettent généralement en œuvre un modèle <b>statistique d’apprentissage automatique</b> tels que ceux de <b>Naive Bayes</b>, de <b>Régression Logistique</b>, <b>SVM</b>.\n",
    "<br><br>\n",
    "Nous utiliserons plusieurs modèles  et nous ferons ensuite du cross_validation afin des les comparer .</p>\n",
    "</ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image.jpg\" style=\"width:800px;height:500px; display: block; margin-left: auto;margin-right: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de passer à l'entraînement des modèles, il reste encore une chose importante à faire qui est la définition des métriques d'évaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"a\" start=\"2\">\n",
    "<li>Métriques d’évaluation </li>\n",
    "<br>\n",
    "Après, Donc, afin d'évaluer les modèles de classification, nous utiliserons ces métriques :\n",
    "<ul>\n",
    "<li><b>Accuracy:</b> quantifie le nombre de prédictions correctes</li>\n",
    "<li><b>Précision:</b> quantifie le nombre de détections positives (avis négatifs) appartenant réellement à la classe positive.</li>\n",
    "<li><b>Rappel:</b> quantifie le nombre détections positives à partir de l’ensemble des exemples positifs du jeu de test.</li>\n",
    "<li><b>Score F1:combine subtilement la précision et le rappel. Il est intéressant et plus intéressant que l’accuracy car le nombre de vrais négatifs (tn) n’est pas pris en compte.</b></li>\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’objectif de notre projet étant de détecter les avis négatifs, nous allons privilégier le rappel par rapport à la précision. Puisqu’en soit, il est préférable de classifier un avis positif comme étant négatif plutôt que de plutôt que l’inverse, c’est-à-dire classifier un avis négatif comme positif.<br><br>\n",
    "Toutefois, nous évaluerons quand même l’ensemble de ces métriques.<br><br>\n",
    "Maintenant nous allons entrainer les modèles et faire les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Définition de la fonction permettant de faire la validation croisée et l'affichage des métriques d'évaluation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_validation(model, X, y):\n",
    "    rappels = cross_val_score(model, X,y, cv=10,scoring='recall')\n",
    "    rappels = pd.Series(rappels)\n",
    "    print(\"Rappels : min=\",rappels.min(),\"  max=\",rappels.max(),\"  moyenne=\",rappels.mean())\n",
    "\n",
    "    precisions = cross_val_score(model, X,y, cv=10,scoring='precision')\n",
    "    precisions = pd.Series(precisions)\n",
    "    print(\"Precisions : min=\",precisions.min(),\"  max=\",precisions.max(),\"  moyenne=\",precisions.mean())\n",
    "\n",
    "    accuracys = cross_val_score(model, X,y, cv=10,scoring='accuracy')\n",
    "    accuracys = pd.Series(accuracys)\n",
    "    print(\"Accuracy : min=\",accuracys.min(),\"  max=\",accuracys.max(),\"  moyenne=\",accuracys.mean())\n",
    "\n",
    "    f1_scores = cross_val_score(model, X,y, cv=10,scoring='f1')\n",
    "    f1_scores = pd.Series(f1_scores)\n",
    "    print(\"F1_score : min=\",f1_scores.min(),\"  max=\",f1_scores.max(),\"  moyenne=\",f1_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Entraînement des modèles et affichage des métriques d'évaluation après validation croisée</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit la variable \"y\" qui correspond aux labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Regression logistique</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Métriques d'évaluation : Regression logistique ******\n",
      "Rappels : min= 0.9704861111111112   max= 0.9872685185185185   moyenne= 0.9805523051641682\n",
      "Precisions : min= 0.926815947569634   max= 0.9555555555555556   moyenne= 0.9377207033401749\n",
      "Accuracy : min= 0.9199609565641776   max= 0.9380185456320156   moyenne= 0.9286026735230749\n",
      "F1_score : min= 0.9539066891512087   max= 0.964073550212164   moyenne= 0.9586197700759405\n"
     ]
    }
   ],
   "source": [
    "#Regression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(multi_class='multinomial')\n",
    "logisticRegression.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Regression logistique ******\")\n",
    "cross_validation(logisticRegression,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Naives Bayes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb Cell 35'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000010?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaive_bayes\u001b[39;00m \u001b[39mimport\u001b[39;00m GaussianNB\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000010?line=3'>4</a>\u001b[0m gaussianNB \u001b[39m=\u001b[39m GaussianNB()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000010?line=4'>5</a>\u001b[0m gaussianNB\u001b[39m.\u001b[39;49mfit(X\u001b[39m.\u001b[39;49mtoarray(), y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000010?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m***** Métriques d\u001b[39m\u001b[39m'\u001b[39m\u001b[39mévaluation : Naives Bayes ******\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000010?line=8'>9</a>\u001b[0m cross_validation(gaussianNB,X,y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py:245\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=221'>222</a>\u001b[0m \u001b[39m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=222'>223</a>\u001b[0m \n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=223'>224</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=241'>242</a>\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=242'>243</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=243'>244</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=244'>245</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=245'>246</a>\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=246'>247</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py:459\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=456'>457</a>\u001b[0m \u001b[39mfor\u001b[39;00m y_i \u001b[39min\u001b[39;00m unique_y:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=457'>458</a>\u001b[0m     i \u001b[39m=\u001b[39m classes\u001b[39m.\u001b[39msearchsorted(y_i)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=458'>459</a>\u001b[0m     X_i \u001b[39m=\u001b[39m X[y \u001b[39m==\u001b[39;49m y_i, :]\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=460'>461</a>\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/workshop/lib/python3.8/site-packages/sklearn/naive_bayes.py?line=461'>462</a>\u001b[0m         sw_i \u001b[39m=\u001b[39m sample_weight[y \u001b[39m==\u001b[39m y_i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Naives Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussianNB = GaussianNB()\n",
    "gaussianNB.fit(X.toarray(), y)\n",
    "\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Naives Bayes ******\")\n",
    "cross_validation(gaussianNB,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Métriques d'évaluation : SVM ******\n",
      "Rappels : min= 0.9594907407407407   max= 0.9803240740740741   moyenne= 0.9725649877222328\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "svmModel = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svmModel.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : SVM ******\")\n",
    "cross_validation(svmModel,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3>\n",
    "Comme explicité un peu plus haut, la métrique qui nous intéresse est le rappel, et pour les différents modèles que nous avons testé celui qui nous permet d’obtenir un meilleur rappel est la régression logistique. <br><br>\n",
    "On a : …. pour la regression logistique, …… pour le Naive Bayes et ……. Pour le SVM. <br><br>\n",
    "Toutefois il est important de noter que le fait d’obtenir un rappel de ….. ne garantit pas que lorsque le modèle sera en production on aura toujours ce même rappel. Mais on sait que cela est probable."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02a3c894954291fda4ab19733d35c869283f9a77a2dca789b03614318f65231a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
